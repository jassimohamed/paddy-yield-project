ğŸŒ¾ Paddy Yield Prediction using Machine Learning

An end-to-end Machine Learning project that predicts paddy (rice) yield using real-world agricultural data from Sri Lanka. This project applies regression algorithms to analyze environmental and agricultural factors affecting crop productivity.

ğŸ“Œ Project Overview

Agriculture plays a vital role in Sri Lankaâ€™s economy. Accurate prediction of paddy yield helps farmers and policymakers make better decisions regarding crop planning and resource management.

This project:

Uses real-world Sri Lankan agricultural data

Performs data cleaning and preprocessing

Implements multiple regression models

Compares model performance

Selects the best-performing model based on evaluation metrics

ğŸ¯ Objectives

Predict paddy yield based on agricultural input features

Compare different regression models

Improve understanding of feature scaling and preprocessing

Select the most accurate and generalizable model

ğŸ› ï¸ Technologies Used

Python

Pandas â€“ Data manipulation

NumPy â€“ Numerical operations

Matplotlib / Seaborn â€“ Data visualization

Scikit-learn â€“ Machine learning models & evaluation

ğŸ“Š Machine Learning Models Implemented

The following regression models were implemented and compared:

Linear Regression

Decision Tree Regressor

K-Nearest Neighbors (KNN)

Random Forest Regressor

ğŸ”„ Project Workflow

Data Collection

Real-world agricultural dataset from Sri Lanka

Data Preprocessing

Handling missing values

Feature selection

Feature scaling using StandardScaler

Model Training

Splitting dataset into training and testing sets

Training multiple regression models

Model Evaluation

Mean Absolute Error (MAE)

Mean Squared Error (MSE)

Root Mean Squared Error (RMSE)

RÂ² Score

Model Comparison

Compared performance of all models

Selected best-performing model based on accuracy and generalization

ğŸ“ˆ Results

Random Forest performed best in terms of prediction accuracy and generalization.

Linear Regression provided a good baseline model.

KNN performance depended on feature scaling.

Decision Tree showed risk of overfitting without tuning.
